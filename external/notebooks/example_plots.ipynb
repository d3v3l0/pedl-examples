{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example plots of PEDL experiment data #\n",
    "\n",
    "Run `pedl e describe --metrics --outdir <outdir> <experiment id>` to generate CSV\n",
    "data."
   ],
   "outputs": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": {},
   "source": [
    "# Set this to get the script started.\n",
    "input_directory = \"/Users/yoavz/Desktop/mnist_conservative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": {},
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading ##\n",
    "\n",
    "Load raw data, basic transformations."
   ],
   "outputs": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": {},
   "source": [
    "dtype_map = {col: str for col in [\"Experiment ID\", \"Trial ID\", \"Step ID\"]}\n",
    "\n",
    "experiments = pd.read_csv(os.path.join(input_directory, \"experiments.csv\"),\n",
    "                          dtype=dtype_map,\n",
    "                          parse_dates=[\"Start Time\", \"End Time\"])\n",
    "trials = pd.read_csv(os.path.join(input_directory, \"trials.csv\"),\n",
    "                     dtype=dtype_map,\n",
    "                     parse_dates=[\"Start Time\", \"End Time\"])\n",
    "steps = pd.read_csv(\n",
    "    os.path.join(input_directory, \"steps.csv\"),\n",
    "    dtype=dtype_map,\n",
    "    parse_dates=[\n",
    "        \"Start Time\", \"End Time\", \"Checkpoint Start Time\", \"Checkpoint End Time\",\n",
    "        \"Validation Start Time\", \"Validation End Time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": {},
   "source": [
    "experiments.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": {},
   "source": [
    "assert len(experiments) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": {},
   "source": [
    "trials.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": {},
   "source": [
    "len(trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": {},
   "source": [
    "steps.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": {},
   "source": [
    "len(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transformations ##\n",
    "\n",
    "Join basic experiment info."
   ],
   "outputs": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": {},
   "source": [
    "trials = pd.merge(trials, experiments[[\"Experiment ID\", \"Description\"]], on=\"Experiment ID\")\n",
    "steps = pd.merge(steps, trials[[\"Trial ID\", \"Experiment ID\", \"Description\"]], on=\"Trial ID\")\n",
    "\n",
    "# Make Step ID numerical\n",
    "steps[\"Step ID\"] = steps[\"Step ID\"].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add start time of the first trial for the experiment."
   ],
   "outputs": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": {},
   "source": [
    "# Note time since experiment start is not very useful, as experiments may not\n",
    "# start their first trial for some time.\n",
    "steps = pd.merge(steps, trials[[\"Experiment ID\", \"Start Time\"]].groupby(\n",
    "    \"Experiment ID\", as_index=False).min().rename(\n",
    "        columns={\"Start Time\": \"First Trial Start Time\"}),\n",
    "                 on=\"Experiment ID\")\n",
    "\n",
    "# Add start time of the trial for the step.\n",
    "steps = pd.merge(steps, steps[[\"Trial ID\", \"Start Time\"]].groupby(\n",
    "    \"Trial ID\", as_index=False).min().rename(\n",
    "        columns={\"Start Time\": \"Trial Start Time\"}),\n",
    "                 on=\"Trial ID\")\n",
    "\n",
    "# Calculate total number of steps associated with each trial ID.\n",
    "# This varies based on the rung the trial ends up in.\n",
    "trials = pd.merge(trials, steps[[\"Trial ID\", \"Step ID\"]].groupby(\n",
    "    \"Trial ID\", as_index=False).max().rename(\n",
    "        columns={\"Step ID\": \"Total Steps In Trial\"}), \n",
    "        on = \"Trial ID\")\n",
    "trials[\"Total Steps In Trial\"] = trials[\"Total Steps In Trial\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model performance graphs ##"
   ],
   "outputs": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": {},
   "source": [
    "from plotnine import (\n",
    "    coord_cartesian, ggplot, aes, geom_col, geom_boxplot, geom_line, geom_point,\n",
    "    scale_y_log10, facet_wrap, guides, facet_grid, ylab, ggtitle, theme_minimal, xlab,\n",
    "    geom_bar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of trials per step size allocation"
   ],
   "outputs": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": {},
   "source": [
    "steps_in_trial_counts = trials.groupby(\"Total Steps In Trial\")\\\n",
    "                              .size()\\\n",
    "                              .reset_index(name=\"Number of Trials\")\n",
    "\n",
    "(ggplot(steps_in_trial_counts, aes(x=\"Total Steps In Trial\", y=\"Number of Trials\")) +\n",
    "  theme_minimal() +\n",
    "  geom_bar(stat=\"identity\") +\n",
    "  ggtitle(\"Trial training performance by step\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trial training performance by step."
   ],
   "outputs": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": {},
   "source": [
    "steps[\"Step ID\"] = steps[\"Step ID\"].astype(int)\n",
    "\n",
    "(ggplot(steps, aes(x=\"Step ID\", y=\"loss\")) +\n",
    "  theme_minimal() +\n",
    "  geom_point(aes(color=\"Trial ID\")) +\n",
    "  geom_line(aes(color=\"Trial ID\")) +\n",
    "  xlab(\"step\") +\n",
    "  ylab(\"loss, log-scaled\") +\n",
    "  scale_y_log10() +\n",
    "  ggtitle(\"Trial training performance by step\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trial training performance by time since step trial start."
   ],
   "outputs": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": {},
   "source": [
    "steps[\"Since Trial Start\"] = (\n",
    "    steps[\"End Time\"] - steps[\"Trial Start Time\"]).dt.total_seconds()\n",
    "\n",
    "(ggplot(steps, aes(x=\"Since Trial Start\",\n",
    "                   y=\"loss\")) +\n",
    "  theme_minimal() +\n",
    "  geom_point(aes(color=\"Trial ID\")) +\n",
    "  geom_line(aes(color=\"Trial ID\")) +\n",
    "  xlab(\"Seconds since trial start\") +\n",
    "  ylab(\"loss, log-scaled\") +\n",
    "  scale_y_log10() +\n",
    "  ggtitle(\"Trial training performance by time from trial start\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trial training performance by time since _first_ trial start."
   ],
   "outputs": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": {},
   "source": [
    "steps[\"Since First Trial Start\"] = (\n",
    "    steps[\"End Time\"] - steps[\"First Trial Start Time\"]).dt.total_seconds()\n",
    "\n",
    "(ggplot(steps, aes(x=\"Since First Trial Start\",\n",
    "                   y=\"loss\")) +\n",
    "  theme_minimal() +\n",
    "  geom_line(aes(color=\"Trial ID\")) +\n",
    "  geom_point(aes(color=\"Trial ID\")) +\n",
    "  xlab(\"Seconds since first trial start\") +\n",
    "  ylab(\"loss, log-scaled\") +\n",
    "  scale_y_log10() +\n",
    "  ggtitle(\"Trial training performance by time from first trial start\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trial validation performance by step."
   ],
   "outputs": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": {},
   "source": [
    "(ggplot(steps.loc[~steps[\"Validation Metric\"].isna()],\n",
    "        aes(x=\"Step ID\", y=\"Validation Metric\")) +\n",
    " theme_minimal() +\n",
    " scale_y_log10() + \n",
    " ylab(\"Validation Metric, log-scaled\") +\n",
    " geom_point(aes(color=\"Trial ID\")) +\n",
    " geom_line(aes(color=\"Trial ID\")) + \n",
    " ggtitle(\"Trial validation performance by step\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment validation performance since first trial start."
   ],
   "outputs": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": {},
   "source": [
    "# Add across-trial step counter `experiment_step_num`\n",
    "best_validation = (\n",
    "    steps\n",
    "    .sort_values(\"End Time\")\n",
    "    .groupby(\"Experiment ID\", as_index=False)\n",
    "    .apply(lambda x: x.reset_index(drop=True).reset_index())\n",
    "    .reset_index(drop=True)\n",
    "    .rename(columns={\"index\": \"Experiment Step Num\"})\n",
    ")\n",
    "# Add min_validation_metric\n",
    "best_validation[\"Min Validation Metric\"] = (\n",
    "    best_validation\n",
    "    .loc[~best_validation[\"Validation Metric\"].isna()]\n",
    "    .sort_values(\"End Time\")\n",
    "    .groupby(\"Experiment ID\", as_index=False)[\"Validation Metric\"].cummin()\n",
    ")\n",
    "\n",
    "best_validation = best_validation[~best_validation[\"Min Validation Metric\"].isna()]\n",
    "best_validation.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": {},
   "source": [
    "(ggplot(best_validation,\n",
    "        aes(x=\"Since First Trial Start\",\n",
    "            y=\"Min Validation Metric\")) +\n",
    "   theme_minimal() +\n",
    "   geom_line(aes(color=\"Experiment ID\")) +\n",
    "   xlab(\"seconds since first trial start\") +\n",
    "   ggtitle(\"Best validation performance since first trial start\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment validation performance by step."
   ],
   "outputs": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": {},
   "source": [
    "(ggplot(best_validation,\n",
    "       aes(x=\"Experiment Step Num\", y=\"Min Validation Metric\")) +\n",
    "  theme_minimal() +\n",
    "  geom_line(aes(color=\"Experiment ID\")) +\n",
    "  ggtitle(\"Best validation performance by step num\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
